# Домашнее задание к занятию "11.03 Микросервисы: подходы"

Вы работаете в крупной компанию, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps специалисту необходимо выдвинуть предложение по организации инфраструктуры, для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- Облачная система;
- Система контроля версий Git;
- Репозиторий на каждый сервис;
- Запуск сборки по событию из системы контроля версий;
- Запуск сборки по кнопке с указанием параметров;
- Возможность привязать настройки к каждой сборке;
- Возможность создания шаблонов для различных конфигураций сборок;
- Возможность безопасного хранения секретных данных: пароли, ключи доступа;
- Несколько конфигураций для сборки из одного репозитория;
- Кастомные шаги при сборке;
- Собственные докер образы для сборки проектов;
- Возможность развернуть агентов сборки на собственных серверах;
- Возможность параллельного запуска нескольких сборок;
- Возможность параллельного запуска тестов;

Обоснуйте свой выбор.

```
Для обеспечения процесса разработки в микросервисной архитектуре предлагается использовать облачную CI/CD платформу GitLab CI/CD. 

GitLab CI/CD обеспечивает хранение исходного кода в системе контроля версий Git и интегрируется с ней для автоматического запуска сборок при изменении кода. Каждый сервис будет иметь свой собственный репозиторий, что обеспечит более гибкую настройку конфигураций для каждого сервиса.

Для безопасного хранения секретных данных, таких как пароли и ключи доступа, GitLab CI/CD предоставляет возможность использования переменных окружения, которые могут быть зашифрованы и переданы в процессе сборки.

GitLab CI/CD также поддерживает создание шаблонов для различных конфигураций сборок и кастомные шаги при сборке, что позволяет гибко настроить процесс сборки для каждого сервиса.

Для ускорения процесса сборки и уменьшения зависимостей от внешних систем, предлагается использовать Docker-образы для сборки проектов. GitLab CI/CD позволяет создавать собственные Docker-образы и использовать их в процессе сборки.

Для обеспечения параллельного запуска нескольких сборок и тестов, GitLab CI/CD поддерживает многопоточность и возможность запуска нескольких задач одновременно.

Кроме того, GitLab CI/CD позволяет развернуть агентов сборки на собственных серверах, что обеспечивает более гибкую настройку инфраструктуры и ускоряет процесс сборки за счет уменьшения задержек при передаче данных между удаленными серверами.

Таким образом, использование GitLab CI/CD обеспечивает гибкость, безопасность и автоматизацию процесса разработки в микросервисной архитектуре.
```

## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- Сбор логов в центральное хранилище со всех хостов обслуживающих систему;
- Минимальные требования к приложениям, сбор логов из stdout;
- Гарантированная доставка логов до центрального хранилища;
- Обеспечение поиска и фильтрации по записям логов;
- Обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- Возможность дать ссылку на сохраненный поиск по записям логов;

Обоснуйте свой выбор.

```
Для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре предлагается использовать ELK-стек (Elasticsearch, Logstash, Kibana) в сочетании с Filebeat.

Filebeat - это агент, который устанавливается на каждом хосте и отслеживает изменения в лог-файлах и/или выводе приложений в stdout. Он отправляет эти данные в Logstash для обработки и фильтрации.

Logstash - это инструмент для сбора, обработки и передачи данных. Он принимает данные от Filebeat, фильтрует их и отправляет в Elasticsearch.

Elasticsearch - это распределенная система поиска и аналитики, которая хранит и индексирует данные. Она используется для хранения лог-файлов и предоставления возможности поиска и фильтрации по записям логов.

Kibana - это веб-интерфейс для Elasticsearch, который позволяет пользователю просматривать, анализировать и визуализировать данные. Он используется для создания пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов и сохранения поисковых запросов.

Для гарантированной доставки логов до центрального хранилища можно использовать механизмы, предоставляемые Filebeat, такие как очередь и повторная отправка в случае ошибки.

Таким образом, использование ELK-стека с Filebeat обеспечивает сбор логов в центральное хранилище со всех хостов обслуживающих систему, минимальные требования к приложениям, гарантированную доставку логов до центрального хранилища, возможность поиска и фильтрации по записям логов, пользовательский интерфейс с возможностью предоставления доступа разработчикам для поиска по записям логов и сохранения поисковых запросов.
```

## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- Сбор метрик со всех хостов, обслуживающих систему;
- Сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- Сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- Сбор метрик, специфичных для каждого сервиса;
- Пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- Пользовательский интерфейс с возможность настраивать различные панели для отслеживания состояния системы;

Обоснуйте свой выбор.

```
Для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре предлагается использовать Prometheus в сочетании с Grafana.

Prometheus - это система мониторинга и алертинга, которая собирает метрики от различных источников, включая хосты и сервисы. Он предоставляет мощные запросы для анализа данных и предупреждений на основе заданных правил.

Grafana - это веб-интерфейс для визуализации данных, который позволяет создавать красивые и информативные дашборды. Он интегрируется с Prometheus и позволяет создавать пользовательские панели для отслеживания состояния системы.

Для сбора метрик со всех хостов можно использовать Node Exporter - агент, который устанавливается на каждом хосте и собирает метрики о ресурсах системы, таких как CPU, RAM, HDD и Network.

Для сбора метрик потребляемых ресурсов для каждого сервиса можно использовать механизмы, предоставляемые самими сервисами. Например, для сбора метрик из контейнеров можно использовать cAdvisor - агент, который собирает метрики о ресурсах контейнеров, включая CPU, RAM, HDD и Network.

Для сбора метрик, специфичных для каждого сервиса, можно использовать экспортеры - агенты, которые собирают метрики из конкретных приложений или сервисов. Например, для сбора метрик из базы данных можно использовать MySQL Exporter.

Таким образом, использование Prometheus с Node Exporter, cAdvisor и экспортерами обеспечивает сбор метрик со всех хостов и сервисов, включая метрики ресурсов и специфичные метрики для каждого сервиса. Интеграция с Grafana позволяет создавать пользовательские панели для отслеживания состояния системы. Пользовательский интерфейс Prometheus предоставляет возможность делать запросы и агрегировать информацию о состоянии системы.
```

## Задача 4: Логи * (необязательная)

Продолжить работу по задаче API Gateway: сервисы используемые в задаче пишут логи в stdout. 

Добавить в систему сервисы для сбора логов Vector + ElasticSearch + Kibana со всех сервисов обеспечивающих работу API.

### Результат выполнения: 

docker compose файл запустив который можно перейти по адресу http://localhost:8081 по которому доступна Kibana.
Логин в Kibana должен быть admin пароль qwerty123456


## Задача 5: Мониторинг * (необязательная)

Продолжить работу по задаче API Gateway: сервисы используемые в задаче предоставляют набор метрик в формате prometheus:

- Сервис security по адресу /metrics
- Сервис uploader по адресу /metrics
- Сервис storage (minio) по адресу /minio/v2/metrics/cluster

Добавить в систему сервисы для сбора метрик (Prometheus и Grafana) со всех сервисов обеспечивающих работу API.
Построить в Graphana dashboard показывающий распределение запросов по сервисам.

### Результат выполнения: 

docker compose файл запустив который можно перейти по адресу http://localhost:8081 по которому доступна Grafana с настроенным Dashboard.
Логин в Grafana должен быть admin пароль qwerty123456

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
